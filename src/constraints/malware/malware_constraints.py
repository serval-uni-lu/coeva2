import pickle
from typing import Union

import autograd.numpy as anp
import numpy as np
import tensorflow as tf

from src.attacks.moeva2.constraints.file_constraints import FileConstraints
from src.constraints.augmented_constraints import AugmentedConstraints


class MalwareConstraints(FileConstraints):
    def fix_features_types(self, x) -> Union[np.ndarray, tf.Tensor]:
        return x

    def __init__(self):
        self.tolerance = 1e-3
        features_path = "./data/malware/features.csv"
        with open("./data/malware/section_names_idx.pkl", "rb") as f:
            self.section_names_idx = pickle.load(f)

        with open("./data/malware/imports_idx.pkl", "rb") as f:
            self.imports_idx = pickle.load(f)

        with open("./data/malware/dll_imports_idx.pkl", "rb") as f:
            self.dll_imports_idx = pickle.load(f)

        with open("./data/malware/freq_idx.pkl", "rb") as f:
            self.freq_idx = pickle.load(f)

        super().__init__(features_path)

    def evaluate_tf2(self, x):
        tol = 1e-3

        # NumberOfSections equals the sum of sections names not set to 'none'(label encoded to 832)
        count = tf.zeros(x.shape[0])
        for i in self.section_names_idx:
            count = count + tf.cast(x[:, i] != 832, tf.float32)
        g1 = tf.math.abs(x[:, 12893] - count)

        g2 = x[:, 13956] - x[:, 10840]

        # The value for FileAlignment should be a power of 2
        m = x[:, 13956]
        g3 = tf.math.abs(
            tf.where(m <= 0.0, tf.zeros(m.shape[0]), tf.math.log(m) / tf.math.log(2.0))
            % 1
        )

        # # api_import_nb is higher than the sum of total imports that we have considered as features
        count = tf.zeros(x.shape[0])
        for i in self.imports_idx:
            count = count + x[:, i]
        g4 = count - x[:, 271]
        #
        # # api_dll_nb is higher than the sum of total dll that we have considered as features
        count = tf.zeros(x.shape[0])
        for i in self.dll_imports_idx:
            count = count + x[:, i]
        g5 = count - x[:, 8607]

        # # Sum of individual byte frequencies is equal to 1. There is a small  difference due to rounding effect
        count = tf.zeros(x.shape[0])
        for i in self.freq_idx:
            count = count + x[:, i]
        g6 = tf.math.abs(1 - count)

        # g7
        count = tf.zeros(x.shape[0])
        for i in self.freq_idx:
            logarithm = tf.math.log(x[:, i]) / tf.math.log(2.0)
            logarithm = tf.where(
                tf.math.is_inf(-logarithm), tf.zeros(logarithm.shape[0]), logarithm
            )
            count = count + x[:, i] * logarithm

        g7 = tf.math.abs(x[:, 23549] + count)

        constraints = tf.stack([g1, g2, g3, g4, g5, g6, g7], 1)

        constraints = tf.clip_by_value(constraints - tol, 0, tf.constant(np.inf))

        return constraints

    def evaluate(self, x: np.ndarray, use_tensors: bool = False):
        # ----- PARAMETERS

        if use_tensors:
            return self.evaluate_tf2(x)

        tol = 1e-3
        # should write a function in utils for this part

        # NumberOfSections equals the sum of sections names not set to 'none'(label encoded to 832)
        g1 = np.absolute(
            x[:, 12893] - np.count_nonzero(x[:, self.section_names_idx] != 832, axis=1)
        )
        #
        # # header_FileAlignment < header_SectionAlignment
        g2 = x[:, 13956] - x[:, 10840]

        # The value for FileAlignment should be a power of 2
        m = x[:, 13956]
        m = np.array(m, dtype=np.float)
        g3 = np.absolute(np.log2(m, out=np.zeros_like(m), where=(m != 0)) % 1 - 0)

        # # api_import_nb is higher than the sum of total imports that we have considered as features
        g4 = np.sum(x[:, self.imports_idx], axis=1) - x[:, 271]
        #
        # # api_dll_nb is higher than the sum of total dll that we have considered as features
        g5 = np.sum(x[:, self.dll_imports_idx], axis=1) - x[:, 8607]

        # # Sum of individual byte frequencies is equal to 1. There is a small  difference due to rounding effect
        g6 = np.absolute(1 - np.sum(x[:, self.freq_idx], axis=1))

        # FileEntropy is related to freqbytes through Shanon entropy
        m = x[:, self.freq_idx]
        m = np.array(m, dtype=np.float)
        # Log of freq_idx
        logarithm = np.log2(m, out=np.zeros_like(m), where=(m != 0))
        g7 = np.absolute(x[:, 23549] + np.sum(x[:, self.freq_idx] * logarithm, axis=1))

        constraints = anp.column_stack([g1, g2, g3, g4, g5, g6, g7])
        constraints[constraints <= tol] = 0.0

        return constraints

    def get_nb_constraints(self) -> int:
        return 7


class MalwareAugmentedConstraints(AugmentedConstraints):
    def __init__(self):
        important_features = np.load("./data/malware_augmented/important_features.npy")
        super().__init__(MalwareConstraints(), important_features)


class MalwareRfAugmentedConstraints(AugmentedConstraints):
    def __init__(self):
        important_features = np.load(
            "./data/malware_rf_augmented/important_features.npy"
        )
        super().__init__(MalwareConstraints(), important_features)
