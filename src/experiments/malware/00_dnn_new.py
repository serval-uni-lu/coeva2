import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    matthews_corrcoef,
    confusion_matrix,
)
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import Dense
from tensorflow.python.keras import Sequential
from tensorflow.python.keras.callbacks import EarlyStopping
from tensorflow.python.keras.layers import Dropout
from tensorflow.keras.losses import BinaryCrossentropy
from src.utils import find_best_threshold

tf.random.set_seed(206)
np.random.seed(205)

kf = StratifiedKFold(n_splits=5, random_state=3105, shuffle=True)


x_train = np.load("./data/malware/training_data/X_train.npy")
x_test = np.load("./data/malware/training_data/X_test.npy")
y_train = np.load("./data/malware/training_data/y_train.npy")
y_test = np.load("./data/malware/training_data/y_test.npy")

scaler = MinMaxScaler()
df = pd.read_csv("./data/malware/features.csv")

x_all = np.concatenate((x_train, x_test))
x_min = df["min"]
x_max = df["max"]
x_min[x_min == "dynamic"] = np.min(x_all, axis=0)[x_min == "dynamic"]
x_max[x_max == "dynamic"] = np.max(x_all, axis=0)[x_max == "dynamic"]
x_min = x_min.astype(np.float).to_numpy().reshape(1, -1)
x_max = x_max.astype(np.float).to_numpy().reshape(1, -1)
x_min = np.min(np.concatenate((x_min, x_all)), axis=0).reshape(1, -1)
x_max = np.max(np.concatenate((x_max, x_all)), axis=0).reshape(1, -1)
scaler.fit(np.concatenate((np.floor(x_min), np.ceil(x_max))))

x_train_s = scaler.transform(x_train)
x_test_s = scaler.transform(x_test)


def print_score(label, prediction):
    print("Test Result:\n================================================")
    print(f"Accuracy Score: {accuracy_score(label, prediction) * 100:.2f}%")
    print("_______________________________________________")
    print("Classification Report:", end="")
    print(f"\tPrecision Score: {precision_score(label, prediction) * 100:.2f}%")
    print(f"\t\t\tRecall Score: {recall_score(label, prediction) * 100:.2f}%")
    print(f"\t\t\tF1 score: {f1_score(label, prediction) * 100:.2f}%")
    print(f"\t\t\tMCC score: {matthews_corrcoef(label, prediction) * 100:.2f}%")
    print("_______________________________________________")
    print(f"Confusion Matrix: \n {confusion_matrix(label, prediction)}\n")


def create_model():

    model = Sequential()
    # input layer
    model.add(Dense(64, activation="relu"))
    # model.add(Dropout(0.2))
    #
    # hidden layer
    model.add(Dense(32, activation="relu"))
    # model.add(Dropout(0.2))
    #

    model.add(Dense(16, activation="relu"))
    # hidden layer
    # model.add(Dense(16, activation="relu"))
    # # model.add(Dropout(0.2))

    # output layer
    model.add(Dense(1, activation="sigmoid"))

    # compile model
    model.compile(
        optimizer="adam",
        loss=BinaryCrossentropy(label_smoothing=0.1),
        metrics=["accuracy", tf.keras.metrics.Recall(), tf.keras.metrics.AUC()],
    )

    return model


avg_mcc = []

# for train_index, test_index in kf.split(x_train, y_train):
#     model = create_model()
#
#     x_train_local, x_test_local = x_train_s[train_index], x_train_s[test_index]
#     y_train_local, y_test_local = y_train[train_index], y_train[test_index]
#
#     early_stop = EarlyStopping(monitor="val_loss", mode="min", verbose=1, patience=25)
#
#     x_train_local, x_val_local, y_train_local, y_val_local = train_test_split(
#         x_train_local,
#         y_train_local,
#         test_size=0.1,
#         random_state=42,
#         stratify=y_train_local,
#     )
#
#     model.fit(
#         x=x_train_local,
#         y=y_train_local,
#         epochs=10,
#         batch_size=64,
#         validation_data=(x_val_local, y_val_local),
#         # shuffle=True,
#         verbose=1,
#         callbacks=[early_stop],
#     )
#
#     y_proba = model.predict_proba(x_test_local).reshape(-1)
#     y_pred = (y_proba >= 0.5).astype(int)
#
#     best_t, best_metrics = find_best_threshold(y_test_local, y_proba)
#     print(f"Best threshold {best_t}")
#     print_score(y_test_local, (y_proba >= best_t).astype(int))


# avg_mcc = np.array(avg_mcc)
# print(avg_mcc.mean())


model = create_model()

early_stop = EarlyStopping(monitor="val_loss", mode="min", verbose=1, patience=25)

x_train_local, x_val_local, y_train_local, y_val_local = train_test_split(
    x_train_s,
    y_train,
    test_size=0.1,
    random_state=42,
    stratify=y_train,
)

print(x_train_local.shape)
model.fit(
    x=x_train_local,
    y=y_train_local,
    epochs=10,
    batch_size=128,
    validation_data=(x_val_local, y_val_local),
    # shuffle=True,
    verbose=1,
    callbacks=[early_stop],
)

y_proba = model.predict_proba(scaler.transform(x_test)).reshape(-1)
print_score(y_test, (y_proba >= 0.5).astype(int))
print(y_proba)
# fig, ax = plt.subplot()
plt.hist(y_proba, bins=100)
plt.savefig("distrib.pdf")

best_t, best_metrics = find_best_threshold(y_test, y_proba)
best_t = 0.9
print(f"Best threshold {best_t}")
y_pred = (y_proba >= best_t).astype(int)
print_score(y_test, y_pred)

candidates_index = (y_test == 1) * (y_test == y_pred) * (y_proba != 1.0)
print(candidates_index.shape)
print(candidates_index.sum())
X_candidate = x_test[candidates_index, :]
print(X_candidate.shape)

print(X_candidate.shape)
np.save("./data/malware/x_attack_candidates_smoothing.npy", X_candidate)

tf.keras.models.save_model(
    model,
    "./models/malware/nn_smoothing.model",
    overwrite=True,
    include_optimizer=True,
    save_format=None,
    signatures=None,
    options=None,
)
joblib.dump(scaler, "./models/malware/scaler_smoothing.joblib")

print((model.predict_proba(scaler.transform(X_candidate)) == 1).sum())
